{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### LSTM-base-language-model\n",
    "\n",
    "- Model:\n",
    "- Data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "\n",
    "import preprocess_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @TODO define a class Data\n",
    "class Data():\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a class Config \n",
    "class Config():\n",
    "  \n",
    "  def __init__(self, path_to_config_file=None):\n",
    "    if path_to_config_file:\n",
    "      read(self, path_to_config_file)\n",
    "    else:\n",
    "      # default constructor \n",
    "      self.is_training = True          # define if the code is run for training or testing \n",
    "      self.sentence_length = 30        # number of words per sentence (ie. how many times we should enroll the network)\n",
    "      self.batch_size = 64             # number of sentences analysed per batch \n",
    "      self.embedding_dimensions = 100  # dimension of the embedding \n",
    "      self.state_size = 512            # dimension of the hidden state \n",
    "      self.max_grad_norm = 10          # max norm of the gradient \n",
    "      self.vocabulary_size = 20004     # vocabulary size \n",
    "      self.number_of_epochs = 10       # number of epochs used during training \n",
    "      self.learning_rate = 1           # learning rate \n",
    "      self.path_to_word2vec =  'wordembeddings-dim100.word2vec' # path to word2vec model \n",
    "      self.use_word2vec_emb = False    # if training is done with Word2Vec or with a rand emb\n",
    "      self.verbose = False             # simple verbose param to follow training \n",
    "      self.save_model = False          # if we should save the model after training \n",
    "      self.restored_model = ''         # path where the model was saved to restore it and test it \n",
    "    \n",
    "  def read(self, path_to_config_file):\n",
    "    # implement fc to read config params \n",
    "    raise ValueError('Method not implemented yet.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "  \n",
    "  def __init__(self, is_training):\n",
    "    # get all the config params \n",
    "    config = Config()\n",
    "    \n",
    "    inputs = tf.placeholder(dtype=tf.float32,\n",
    "                            shape=[config.batch_size, config.sentence_length, config.embedding_dimensions],\n",
    "                            name='inputs')\n",
    "    \n",
    "    labels = tf.placeholder(dtype=tf.int32,\n",
    "                            shape=[config.batch_size, config.sentence_length],\n",
    "                            name='labels')\n",
    "\n",
    "    # construct basic LSTM cell \n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(config.state_size)\n",
    "    # build-in tensorflow function to enroll the LSTM\n",
    "    self.initial_state = lstm_cell.zero_state(config.batch_size, tf.float32)\n",
    "    inputs = tf.unstack(inputs, num=config.sentence_length, axis=1)\n",
    "    output, state = tf.nn.static_rnn(lstm_cell, inputs, dtype=tf.float32)\n",
    "    output = tf.reshape(output, [config.sentence_length*config.batch_size, config.state_size])\n",
    "    # project state size on the vocab size dim = state_size x vocabulary_size \n",
    "    weights = tf.get_variable(\"weights\",\n",
    "                              [config.state_size, config.vocabulary_size],\n",
    "                              dtype=tf.float32,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    # add a bias dim = vocabulary_size \n",
    "    bias = tf.get_variable(\"bias\",\n",
    "                           [config.vocabulary_size],\n",
    "                           dtype=tf.float32,\n",
    "                           initializer=tf.contrib.layers.xavier_initializer())\n",
    "    # compute the logits \n",
    "    logits = tf.matmul(output, weights) + bias\n",
    "    # reshape logits to dim = batch_size x num_steps x vocabulary_size \n",
    "    logits = tf.reshape(logits, [config.sentence_length,\n",
    "                                 config.batch_size,\n",
    "                                 config.vocabulary_size])\n",
    "    # define proba with softmax layer with dim = batch_size x num_steps x vocabulary_size \n",
    "    self.probabilities = tf.nn.softmax(logits)\n",
    "    \n",
    "    if not is_training:\n",
    "      return \n",
    "    \n",
    "    # should probably reshape before \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels,\n",
    "                                                  logits)\n",
    "    self.loss = tf.reduce_sum(loss)\n",
    "    \n",
    "    # optimizer and minimize ...\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=config.learning_rate)\n",
    "\n",
    "    minimize = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm_graph(lstm_cell, input_batch):\n",
    "  # cell: tensorflow LSTM object\n",
    "  # batch: tensorflow of shape sent_len x batch_size x emb_dim\n",
    "  \n",
    "  # return value is a N-D tensor of shape [batch_size, state_size] filled with zeros.\n",
    "  initial_state = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "  \n",
    "  # init state is the init one \n",
    "  state = initial_state\n",
    "\n",
    "  # where to store the cell_output after each time_step \n",
    "  outputs = []\n",
    "  \n",
    "  for time_step in range(num_steps):\n",
    "    # see if there is a better way to reuse the variables \n",
    "    if time_step > 0:\n",
    "      tf.get_variable_scope().reuse_variables()\n",
    "    # given the current state 'state' and the input_batch, compute the new state and the cell_output \n",
    "    #  - cell_output: (batch_size, output_size) What is output_size here ??\n",
    "    #  - state:  (batch_size, state_size)\n",
    "    cell_output, state = lstm_cell(input_batch[:, time_step, :], state)\n",
    "    outputs.append(cell_output)\n",
    "\n",
    "  # tf.reshape(tensor, shape)\n",
    "  # tf.concat(values, axis)\n",
    "  output = tf.reshape(tf.concat(outputs, 1), [-1, state_size])\n",
    "  \n",
    "  return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO KEEP (TO INTEGRATE IN THE MODEL)\n",
    "\n",
    "# our own implementation of tf.nn.static_rnn\n",
    "output, state = build_lstm_graph(lstm_celllstm_cell, batch)\n",
    "\n",
    "# Calling minimize() takes care of both computing the gradients and applying them to the variables.\n",
    "# If you want to process the gradients before applying them you can instead use the optimizer in four steps:\n",
    "#   1- Define an optimizer \n",
    "#   2- Compute the gradients with compute_gradients().\n",
    "#   3- Process the gradients as you wish.\n",
    "#   4- Apply the processed gradients with apply_gradients()\n",
    "\n",
    "# So instead of:\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "minimize =  optimizer.minimize(loss)\n",
    "\n",
    "# Use:\n",
    "# 1) define the optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# 2) compute the gradients\n",
    "gradients_and_vars = optimizer.compute_gradients(loss)\n",
    "# 3) process the gradient \n",
    "processed_gradients_and_vars = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients_and_vars]\n",
    "# 4) apply the gradients.\n",
    "train_optimizer = optimizer.apply_gradients(processed_gradients_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Number of sentences loaded:  9753\n",
      "Loading external embeddings from wordembeddings-dim100.word2vec\n",
      "Generated embedding for 20004 words\n",
      "9.90123462677\n",
      "Batch: 0\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "19.8024559021\n",
      "Batch: 1\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "29.7036294937\n",
      "Batch: 2\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "39.6044902802\n",
      "Batch: 3\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "49.5055561066\n",
      "Batch: 4\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "59.4063119888\n",
      "Batch: 5\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "69.3077945709\n",
      "Batch: 6\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "79.2083902359\n",
      "Batch: 7\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "89.1094522476\n",
      "Batch: 8\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "99.0104694366\n",
      "Batch: 9\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "108.911548615\n",
      "Batch: 10\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "118.812353134\n",
      "Batch: 11\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "128.713433266\n",
      "Batch: 12\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "138.614686966\n",
      "Batch: 13\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "148.515967369\n",
      "Batch: 14\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "158.417279243\n",
      "Batch: 15\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "168.31860733\n",
      "Batch: 16\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "178.219551086\n",
      "Batch: 17\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "188.120456696\n",
      "Batch: 18\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "198.021522522\n",
      "Batch: 19\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "207.922392845\n",
      "Batch: 20\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "217.823719025\n",
      "Batch: 21\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "227.724692345\n",
      "Batch: 22\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "237.625593185\n",
      "Batch: 23\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "247.526309967\n",
      "Batch: 24\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "257.427282333\n",
      "Batch: 25\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "267.328142166\n",
      "Batch: 26\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "277.229319572\n",
      "Batch: 27\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "287.13010025\n",
      "Batch: 28\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "297.030932426\n",
      "Batch: 29\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "306.932359695\n",
      "Batch: 30\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "316.833608627\n",
      "Batch: 31\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "326.734731674\n",
      "Batch: 32\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "336.635926247\n",
      "Batch: 33\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "346.536948204\n",
      "Batch: 34\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "356.438428879\n",
      "Batch: 35\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "366.339202881\n",
      "Batch: 36\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "376.240291595\n",
      "Batch: 37\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "386.14136219\n",
      "Batch: 38\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "396.041894913\n",
      "Batch: 39\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "405.943185806\n",
      "Batch: 40\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "415.844768524\n",
      "Batch: 41\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "425.74569416\n",
      "Batch: 42\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "435.64688015\n",
      "Batch: 43\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "445.547696114\n",
      "Batch: 44\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "455.449095726\n",
      "Batch: 45\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "465.349945068\n",
      "Batch: 46\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "475.25091362\n",
      "Batch: 47\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "485.1519804\n",
      "Batch: 48\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "495.053275108\n",
      "Batch: 49\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "504.954184532\n",
      "Batch: 50\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "514.8552742\n",
      "Batch: 51\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "524.756681442\n",
      "Batch: 52\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "534.658006668\n",
      "Batch: 53\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "544.55900383\n",
      "Batch: 54\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "554.459961891\n",
      "Batch: 55\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "564.361151695\n",
      "Batch: 56\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "574.262406349\n",
      "Batch: 57\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "584.163281441\n",
      "Batch: 58\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "594.064476013\n",
      "Batch: 59\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "603.965308189\n",
      "Batch: 60\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "613.866475105\n",
      "Batch: 61\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "623.767107964\n",
      "Batch: 62\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "633.668525696\n",
      "Batch: 63\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "643.569765091\n",
      "Batch: 64\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "653.470495224\n",
      "Batch: 65\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "663.371876717\n",
      "Batch: 66\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "673.27323246\n",
      "Batch: 67\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "683.174265862\n",
      "Batch: 68\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "693.075231552\n",
      "Batch: 69\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "702.976132393\n",
      "Batch: 70\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "712.876983643\n",
      "Batch: 71\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "722.778096199\n",
      "Batch: 72\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "732.679062843\n",
      "Batch: 73\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "742.580286026\n",
      "Batch: 74\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "752.481380463\n",
      "Batch: 75\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "762.382096291\n",
      "Batch: 76\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "772.283213615\n",
      "Batch: 77\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "782.184017181\n",
      "Batch: 78\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "792.085318565\n",
      "Batch: 79\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "801.986474037\n",
      "Batch: 80\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "811.887564659\n",
      "Batch: 81\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "821.788643837\n",
      "Batch: 82\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "831.689949036\n",
      "Batch: 83\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "841.590559006\n",
      "Batch: 84\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "851.49166584\n",
      "Batch: 85\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "861.392731667\n",
      "Batch: 86\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "871.293745041\n",
      "Batch: 87\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "881.19468689\n",
      "Batch: 88\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "891.095395088\n",
      "Batch: 89\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "900.996631622\n",
      "Batch: 90\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "910.897726059\n",
      "Batch: 91\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "920.798728943\n",
      "Batch: 92\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "930.699919701\n",
      "Batch: 93\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "940.600908279\n",
      "Batch: 94\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "950.501854897\n",
      "Batch: 95\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "960.402839661\n",
      "Batch: 96\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "970.303449631\n",
      "Batch: 97\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "980.204353333\n",
      "Batch: 98\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "990.10552597\n",
      "Batch: 99\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1000.00641155\n",
      "Batch: 100\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1009.90709496\n",
      "Batch: 101\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1019.80775738\n",
      "Batch: 102\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1029.70878696\n",
      "Batch: 103\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1039.6097126\n",
      "Batch: 104\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1049.51070976\n",
      "Batch: 105\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1059.41168404\n",
      "Batch: 106\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1069.31250858\n",
      "Batch: 107\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079.2135725\n",
      "Batch: 108\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1089.11439419\n",
      "Batch: 109\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1099.01522827\n",
      "Batch: 110\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1108.91632652\n",
      "Batch: 111\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1118.81721592\n",
      "Batch: 112\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1128.71816158\n",
      "Batch: 113\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1138.61888599\n",
      "Batch: 114\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1148.51953888\n",
      "Batch: 115\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1158.42061138\n",
      "Batch: 116\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1168.32167625\n",
      "Batch: 117\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1178.22314358\n",
      "Batch: 118\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1188.12458229\n",
      "Batch: 119\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1198.02539349\n",
      "Batch: 120\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1207.92630768\n",
      "Batch: 121\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1217.827384\n",
      "Batch: 122\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1227.72839546\n",
      "Batch: 123\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1237.62971401\n",
      "Batch: 124\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1247.53068447\n",
      "Batch: 125\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1257.43210602\n",
      "Batch: 126\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1267.33332634\n",
      "Batch: 127\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1277.23469734\n",
      "Batch: 128\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1287.13572884\n",
      "Batch: 129\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1297.03696918\n",
      "Batch: 130\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1306.93801689\n",
      "Batch: 131\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1316.83916855\n",
      "Batch: 132\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1326.74016857\n",
      "Batch: 133\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1336.64119911\n",
      "Batch: 134\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1346.54226685\n",
      "Batch: 135\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1356.44296837\n",
      "Batch: 136\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1366.3440752\n",
      "Batch: 137\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1376.24498367\n",
      "Batch: 138\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1386.14624405\n",
      "Batch: 139\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1396.04694557\n",
      "Batch: 140\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1405.94808674\n",
      "Batch: 141\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1415.84932804\n",
      "Batch: 142\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1425.7504797\n",
      "Batch: 143\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1435.65148258\n",
      "Batch: 144\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1445.55263805\n",
      "Batch: 145\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1455.45383263\n",
      "Batch: 146\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1465.35477448\n",
      "Batch: 147\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1475.25581074\n",
      "Batch: 148\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1485.15683651\n",
      "Batch: 149\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1495.05748749\n",
      "Batch: 150\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1504.95854378\n",
      "Batch: 151\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "Epoch:  0 with perplexity:  1.391016491\n",
      "9.90123462677\n",
      "Batch: 0\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "19.8024559021\n",
      "Batch: 1\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "29.7036294937\n",
      "Batch: 2\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "39.6044902802\n",
      "Batch: 3\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "49.5055561066\n",
      "Batch: 4\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "59.4063119888\n",
      "Batch: 5\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "69.3077945709\n",
      "Batch: 6\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "79.2083902359\n",
      "Batch: 7\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "89.1094522476\n",
      "Batch: 8\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "99.0104694366\n",
      "Batch: 9\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "108.911548615\n",
      "Batch: 10\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "118.812353134\n",
      "Batch: 11\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "128.713433266\n",
      "Batch: 12\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "138.614686966\n",
      "Batch: 13\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "148.515967369\n",
      "Batch: 14\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "158.417279243\n",
      "Batch: 15\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "168.31860733\n",
      "Batch: 16\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "178.219551086\n",
      "Batch: 17\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "188.120456696\n",
      "Batch: 18\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "198.021522522\n",
      "Batch: 19\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "207.922392845\n",
      "Batch: 20\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "217.823719025\n",
      "Batch: 21\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "227.724692345\n",
      "Batch: 22\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "237.625593185\n",
      "Batch: 23\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "247.526309967\n",
      "Batch: 24\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "257.427282333\n",
      "Batch: 25\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "267.328142166\n",
      "Batch: 26\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "277.229319572\n",
      "Batch: 27\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "287.13010025\n",
      "Batch: 28\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "297.030932426\n",
      "Batch: 29\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "306.932359695\n",
      "Batch: 30\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "316.833608627\n",
      "Batch: 31\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "326.734731674\n",
      "Batch: 32\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "336.635926247\n",
      "Batch: 33\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "346.536948204\n",
      "Batch: 34\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "356.438428879\n",
      "Batch: 35\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "366.339202881\n",
      "Batch: 36\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "376.240291595\n",
      "Batch: 37\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "386.14136219\n",
      "Batch: 38\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "396.041894913\n",
      "Batch: 39\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "405.943185806\n",
      "Batch: 40\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "415.844768524\n",
      "Batch: 41\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "425.74569416\n",
      "Batch: 42\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "435.64688015\n",
      "Batch: 43\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "445.547696114\n",
      "Batch: 44\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "455.449095726\n",
      "Batch: 45\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "465.349945068\n",
      "Batch: 46\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "475.25091362\n",
      "Batch: 47\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "485.1519804\n",
      "Batch: 48\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "495.053275108\n",
      "Batch: 49\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "504.954184532\n",
      "Batch: 50\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "514.8552742\n",
      "Batch: 51\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "524.756681442\n",
      "Batch: 52\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "534.658006668\n",
      "Batch: 53\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "544.55900383\n",
      "Batch: 54\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "554.459961891\n",
      "Batch: 55\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "564.361151695\n",
      "Batch: 56\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "574.262406349\n",
      "Batch: 57\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "584.163281441\n",
      "Batch: 58\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "594.064476013\n",
      "Batch: 59\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "603.965308189\n",
      "Batch: 60\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "613.866475105\n",
      "Batch: 61\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "623.767107964\n",
      "Batch: 62\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "633.668525696\n",
      "Batch: 63\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "643.569765091\n",
      "Batch: 64\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653.470495224\n",
      "Batch: 65\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "663.371876717\n",
      "Batch: 66\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "673.27323246\n",
      "Batch: 67\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "683.174265862\n",
      "Batch: 68\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "693.075231552\n",
      "Batch: 69\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "702.976132393\n",
      "Batch: 70\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "712.876983643\n",
      "Batch: 71\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "722.778096199\n",
      "Batch: 72\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "732.679062843\n",
      "Batch: 73\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "742.580286026\n",
      "Batch: 74\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "752.481380463\n",
      "Batch: 75\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "762.382096291\n",
      "Batch: 76\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "772.283213615\n",
      "Batch: 77\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "782.184017181\n",
      "Batch: 78\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "792.085318565\n",
      "Batch: 79\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "801.986474037\n",
      "Batch: 80\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "811.887564659\n",
      "Batch: 81\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "821.788643837\n",
      "Batch: 82\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "831.689949036\n",
      "Batch: 83\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "841.590559006\n",
      "Batch: 84\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "851.49166584\n",
      "Batch: 85\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "861.392731667\n",
      "Batch: 86\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "871.293745041\n",
      "Batch: 87\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "881.19468689\n",
      "Batch: 88\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "891.095395088\n",
      "Batch: 89\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "900.996631622\n",
      "Batch: 90\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "910.897726059\n",
      "Batch: 91\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "920.798728943\n",
      "Batch: 92\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "930.699919701\n",
      "Batch: 93\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "940.600908279\n",
      "Batch: 94\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "950.501854897\n",
      "Batch: 95\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "960.402839661\n",
      "Batch: 96\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "970.303449631\n",
      "Batch: 97\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "980.204353333\n",
      "Batch: 98\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "990.10552597\n",
      "Batch: 99\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1000.00641155\n",
      "Batch: 100\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1009.90709496\n",
      "Batch: 101\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1019.80775738\n",
      "Batch: 102\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1029.70878696\n",
      "Batch: 103\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1039.6097126\n",
      "Batch: 104\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1049.51070976\n",
      "Batch: 105\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1059.41168404\n",
      "Batch: 106\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1069.31250858\n",
      "Batch: 107\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1079.2135725\n",
      "Batch: 108\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1089.11439419\n",
      "Batch: 109\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1099.01522827\n",
      "Batch: 110\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1108.91632652\n",
      "Batch: 111\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1118.81721592\n",
      "Batch: 112\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1128.71816158\n",
      "Batch: 113\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1138.61888599\n",
      "Batch: 114\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1148.51953888\n",
      "Batch: 115\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1158.42061138\n",
      "Batch: 116\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1168.32167625\n",
      "Batch: 117\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1178.22314358\n",
      "Batch: 118\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1188.12458229\n",
      "Batch: 119\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1198.02539349\n",
      "Batch: 120\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1207.92630768\n",
      "Batch: 121\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1217.827384\n",
      "Batch: 122\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1227.72839546\n",
      "Batch: 123\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1237.62971401\n",
      "Batch: 124\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1247.53068447\n",
      "Batch: 125\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1257.43210602\n",
      "Batch: 126\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1267.33332634\n",
      "Batch: 127\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n",
      "1277.23469734\n",
      "Batch: 128\n",
      "Batch data:  (64, 30, 100)\n",
      "Batch labels:  (64, 30)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def main():\n",
    "  \n",
    "  # get config execution\n",
    "  config = Config()\n",
    "  # get frequent words list \n",
    "  frequent_words = preprocess_helper.load_frequent_words('google-10000-english/20k.txt')\n",
    "  # get testing and training data\n",
    "  #train_data, train_labels = preprocess_helper.load_and_process_data('data/sentences.train', frequent_words, 28)\n",
    "  all_train_data, all_train_labels = preprocess_helper.load_and_process_data('data/sentences.eval', frequent_words, 28)\n",
    "  # compute number of batches\n",
    "  number_of_batches = int(len(all_train_data)/config.batch_size)\n",
    "  # init tensor flow session \n",
    "  session = tf.Session()\n",
    "\n",
    "  with session.as_default():\n",
    "    \n",
    "    # get the embedding matrix (with rand init emb or with word2vec)\n",
    "    vocab = {word: i for i,word in enumerate(frequent_words)}\n",
    "    with tf.variable_scope(\"Embedding\", reuse=tf.AUTO_REUSE):\n",
    "      embedding = tf.get_variable(\"embedding\",\n",
    "                                  [config.vocabulary_size, config.embedding_dimensions],\n",
    "                                  dtype=tf.float32)\n",
    "      load_embedding(session, vocab, embedding, config)\n",
    "      \n",
    "      # placeholder to get train_input and labels (batch_size x sent_len)\n",
    "      train_input_ph = tf.placeholder(tf.int64,\n",
    "                                      [config.batch_size, config.sentence_length],\n",
    "                                      name='train_input_ph')\n",
    "      train_labels_ph = tf.placeholder(tf.int64,\n",
    "                                      [config.batch_size, config.sentence_length],\n",
    "                                      name='train_labels_ph')\n",
    "\n",
    "      # generate 'usable' input_data for TF \n",
    "      embedded_train_input = tf.nn.embedding_lookup(embedding,\n",
    "                                                    train_input_ph)\n",
    "    \n",
    "    frequent_words_as_tensor = tf.convert_to_tensor(frequent_words)\n",
    "    train_data_as_tensor = tf.convert_to_tensor(all_train_data)\n",
    "    train_labels_as_tensor = tf.convert_to_tensor(all_train_labels)\n",
    "\n",
    "    train_data_as_indices = tf.contrib.lookup.string_to_index(train_data_as_tensor,\n",
    "                                                              mapping=frequent_words_as_tensor,\n",
    "                                                              default_value=2004)\n",
    "    train_labels_as_indices = tf.contrib.lookup.string_to_index(train_labels_as_tensor,\n",
    "                                                                mapping=frequent_words_as_tensor,\n",
    "                                                                default_value=2004)\n",
    "    tf.tables_initializer().run()\n",
    "    \n",
    "    # Create a model instance \n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    with tf.variable_scope(\"Model\", reuse=tf.AUTO_REUSE, initializer=initializer):\n",
    "      # create an Model instance \n",
    "      model = Model(is_training=config.is_training)\n",
    "      # init \n",
    "      init = tf.global_variables_initializer()\n",
    "      session.run(init)\n",
    "\n",
    "      # loop over each epoch \n",
    "      for epoch_id in range(config.number_of_epochs):\n",
    "        # define perplexity and total_loss across all the batches\n",
    "        perplexity = 0\n",
    "        total_loss = 0\n",
    "        total_iters = 0\n",
    "        # loop over each batch \n",
    "        for batch_id in range(number_of_batches):\n",
    "          \n",
    "          # extract batch_size sentences from the training data \n",
    "          training_batch = train_data_as_indices[batch_id*config.batch_size:(batch_id+1)*config.batch_size]\n",
    "          training_batch = tf.get_session_handle(training_batch)\n",
    "          training_batch = session.run(training_batch)\n",
    "          training_batch = session.run(embedded_train_input, {train_input_ph: training_batch})\n",
    "\n",
    "          training_labels = train_labels_as_indices[batch_id*config.batch_size:(batch_id+1)*config.batch_size,:]\n",
    "          training_labels = session.run(training_labels)\n",
    "\n",
    "          # variable to fect in the graph \n",
    "          fetches = {\n",
    "            \"loss\": model.loss,\n",
    "            \"probabilities\": model.probabilities\n",
    "          }\n",
    "\n",
    "          # input variables of the graph \n",
    "          feed_dict = {\n",
    "            \"Model/inputs:0\": training_batch,\n",
    "            \"Model/labels:0\": training_labels\n",
    "          }\n",
    "\n",
    "          # Feed the model with the training_batch and the training_labels \n",
    "          vals = session.run(fetches=fetches, feed_dict=feed_dict)\n",
    "                    \n",
    "          total_loss += vals[\"loss\"]\n",
    "          print(total_loss)\n",
    "          total_iters += config.sentence_length\n",
    "          \n",
    "          print('Batch:', batch_id)\n",
    "          print('Batch data: ',np.shape(training_batch))\n",
    "          print('Batch labels: ', np.shape(training_labels))\n",
    "          \n",
    "        print('Epoch: ',epoch_id, 'with perplexity: ', np.exp(total_loss/float(total_iters)))\n",
    "        \n",
    "\n",
    "  # finally close the session ...\n",
    "  session.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "  #tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables_names = [v.name for v in tf.trainable_variables()]\n",
    "#values = session.run(variables_names)\n",
    "#for k, v in zip(variables_names, values):\n",
    "#    print(\"Variable: \", k)\n",
    "#    print(\"Shape: \", v.shape)\n",
    "#    print(v)\n",
    "\n",
    "\n",
    "#for op in tf.get_default_graph().get_operations():\n",
    "#  print(str(op.name))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequent_words = preprocess_helper.load_frequent_words('google-10000-english/20k.txt')\n",
    "\n",
    "def load_embedding(session, vocab, emb, config):\n",
    "  '''\n",
    "    session        Tensorflow session object\n",
    "    vocab          A dictionary mapping token strings to vocabulary IDs\n",
    "    emb            Embedding tensor of shape vocabulary_size x dim_embedding\n",
    "    path           Path to embedding file\n",
    "    dim_embedding  Dimensionality of the external embedding.\n",
    "  '''\n",
    "  print(\"Loading external embeddings from %s\" % config.path_to_word2vec)\n",
    "  model = gensim.models.KeyedVectors.load_word2vec_format(config.path_to_word2vec, binary=False)\n",
    "  external_embedding = np.zeros(shape=(config.vocabulary_size, config.embedding_dimensions))\n",
    "  matches = 0\n",
    "  for tok, idx in vocab.items():\n",
    "    if config.use_word2vec_emb and tok in model.vocab:\n",
    "      external_embedding[idx] = model[tok]\n",
    "      matches += 1\n",
    "    else:\n",
    "      if config.verbose:\n",
    "        print(\"%s not in embedding file\" % tok)\n",
    "      external_embedding[idx] = np.random.uniform(low=-0.25, high=0.25, size=config.embedding_dimensions)\n",
    "  \n",
    "  if config.use_word2vec_emb:\n",
    "    print(\"%d words out of %d could be loaded\" % (matches, config.vocabulary_size))\n",
    "  else:\n",
    "    print(\"Generated embedding for %d words\" % config.vocabulary_size)\n",
    "\n",
    "  pretrained_embeddings = tf.placeholder(tf.float32,\n",
    "                                         [None, None],\n",
    "                                         name='pretrained_embedding')\n",
    "  assign_op = emb.assign(pretrained_embeddings)\n",
    "  session.run(assign_op, {pretrained_embeddings: external_embedding})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
